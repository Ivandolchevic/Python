{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### A python script to collect all of the .csv files from DataCamp ###\n",
    "### and copy them to a folder named Data in the currect directory. ###\n",
    "### Created 3/3/18 by David coxon ###\n",
    "\n",
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "codebook='Data/importedcsv.txt'\n",
    "now = datetime.datetime.now()\n",
    "now = str(now)\n",
    "# Specify url\n",
    "url = 'https://www.datacamp.com/courses'\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc, \"lxml\")\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags=soup.find_all('a')\n",
    "\n",
    "# Extract the /courses pages\n",
    "courses=[]\n",
    "pattern = re.compile(\"/courses//*\")\n",
    "for link in a_tags:\n",
    "    match = re.findall(pattern, str(link))\n",
    "    if match:\n",
    "        courses.append(link.get('href'))   \n",
    "\n",
    "# iterate over list of courses getting links to csv files\n",
    "csv=[]     \n",
    "for course in courses:    \n",
    "    \n",
    "    # Specify url\n",
    "    url = \"https://datacamp.com\"+course    \n",
    "    # Package the request, send the request and catch the response: r\n",
    "    r = requests.get(url)\n",
    "    # Extracts the response as html: html_doc\n",
    "    html_doc = r.text\n",
    "\n",
    "    # create a BeautifulSoup object from the HTML: soup\n",
    "    soup = BeautifulSoup(html_doc, \"lxml\")\n",
    "    \n",
    "    # Find all 'a' tags (which define hyperlinks): a_tags\n",
    "    a_tags1=soup.find_all('a')\n",
    "\n",
    "    # append the URLs to csv list\n",
    "    pattern = re.compile(\"csv/*\")        \n",
    "    for link in a_tags1:\n",
    "        match = re.findall(pattern, str(link))\n",
    "        if match:\n",
    "            csv.append(link.get('href')) \n",
    "\n",
    "# open Csv files and copy to Local device           \n",
    "for file in csv:\n",
    "    y=file.split('/')\n",
    "    destination='Data/'+(y[-1])\n",
    "    df=pd.read_csv(file)\n",
    "    df.to_csv(destination)\n",
    "\n",
    "    # Document which files were collected\n",
    "    with open(codebook, \"a\") as f:\n",
    "        f.write(\"\\nsource : \" + file + \" dated collected : \" + now)\n",
    "print(str(len(csv)) + \" csv files checked!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
